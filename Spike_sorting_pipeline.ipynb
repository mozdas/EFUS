{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Sorting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs you through the process of semi-automatic spike sorting pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Copy your data from HDD to SSD \n",
    "\n",
    "First things first! Before any data analysis, we need to <b>copy the data from the hard drive where the raw data is stored to the 1 TB SSD on this computer that is designated as the workspace</b>. This is asked for two reasons: \n",
    "\n",
    "<ol type=\"1\">\n",
    "<li>There is a remarkable difference between the speed of reading data from the HDD vs. SSD</li>\n",
    "<li>There are some by-products of the data analysis that should be deleted at the end of the analysis. If these files are stored in the HDD, Dropbox tries to synchonize all those files as well. And also some times these files are forgotten to be deleted and end up taking precious space on the HDD where more novel, raw data could have been stored.</li>\n",
    "</ol>\n",
    "\n",
    "<b> IF </b> you have completed this step, please continue with the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generate parameter dictionary for all recording sessions\n",
    "\n",
    "Next, we will need to generate pickle files named <i> paramsDict.p </i> for each recording session in your experiment. These pickle files contain crucial parameters related to data acquisition and your preferences on the details of how the data should be analyzed. For this procedure, please <b> run the block below </b> to launch the Jupyter notebook (Python 3) for generating the parameter dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter notebook './Generate_dict_for_experiment.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.5) Restart kernel\n",
    "\n",
    "Since no bash or python command to this date exists for properly closing a jupyter notebook, from the <i> Kernel </i> tab above, select <i> Restart & Clear Output </i> to restart the kernel. That will not be an issue since the <i> paramsDict.p </i> files are already generated and saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run the main analysis function on the data \n",
    "\n",
    "We are ready to perform the analysis on the data. Please <b> specify the path (with / at the end) </b> to the folder that contains the folders for all recording sessions (i.e. the folder right above the folders of recording sessions in hierarchy) and then <b> run the following line of code </b> to run the script <i> analyze_all_recording_sessions.py </i> which will run the <i> main </i> function in the <i> main_tetrode.py </i>. You can check the scripts for the details of the steps running on the background. Make sure to switch on the <b> swap memory </b> before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(klusta) (klusta) (klusta) /home/yaniklab/miniconda3/envs/klusta/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/yaniklab/miniconda3/envs/klusta/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Currently analyzing:/media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_05_04_FUSs1_EphysM1_E-FUS_NBBB80/FUS_Muscimol_180504_122329\n",
      "start reading out and analyzing trodes\n",
      "Start time: 2018-07-16 17:45:02.213586\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\n",
      "Reading Intan Technologies RHD2000 Data File, Version 1.5\n",
      "\n",
      "Found 32 amplifier channels.\n",
      "Found 3 auxiliary input channels.\n",
      "Found 1 supply voltage channel.\n",
      "Found 8 board ADC channels.\n",
      "Found 16 board digital input channels.\n",
      "Found 0 board digital output channels.\n",
      "Found 0 temperature sensors channels.\n",
      "\n",
      "Header file contains no data.  Amplifiers were sampled at 30.00 kS/s.\n",
      "Done!  Elapsed time: 0.0 seconds\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"analyze_all_recording_sessions.py\", line 46, in <module>\n",
      "    main(p) #Running the main function on the recording session.\n",
      "  File \"/home/yaniklab/Desktop/akgokce/efus/main.py\", line 45, in main\n",
      "    group_file = read_group(probe,group,p)\n",
      "  File \"/home/yaniklab/Desktop/akgokce/efus/utils/reading_utils.py\", line 95, in read_group\n",
      "    group_file[trode] = read_amplifier_dat_file(electrode_path)\n",
      "  File \"/home/yaniklab/Desktop/akgokce/efus/utils/reading_utils.py\", line 29, in read_amplifier_dat_file\n",
      "    amplifier_file = raw_array * 0.195 #converting from int16 to microvolts\n",
      "KeyboardInterrupt\n",
      "(klusta) "
     ]
    }
   ],
   "source": [
    "source activate klusta #Activating the klustakwik virtual environment\n",
    "#Specify the path here!\n",
    "PATHEXP=\"/media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_05_04_FUSs1_EphysM1_E-FUS_NBBB80/\" #with / at the end\n",
    "echo $PATHEXP|python analyze_all_recording_sessions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Initial manual clustering\n",
    "\n",
    "As we have run the Klustakwik, now we are ready to generate figures and  extract results for this experiment. It is time to take a look at the results of the initial clustering to <b> eliminate obvious noise clusters</b>. At this stage, <b>please do not attempt to make conclusive judgements</b> about the cluster identities since it will happen at a later step that is also guided by our custom GUI.\n",
    "\n",
    "The cell below activates the klustaviewa environment and also provides a list of recording session folders inside the experiment folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(klusta) (klusta) (klusta) (klustaviewa) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "source activate klusta #Activating the klustakwik virtual environment\n",
    "PATHEXP=\"/media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_05_04_FUSs1_EphysM1_E-FUS_NBBB80/\" #with / at the end\n",
    "\n",
    "source activate klustaviewa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the klustaviewa command on the tetrodes/shanks of every recording session that you would like to perform spike sorting on, from the experiment. <b>Run the klustaviewa command on the .kwik file inside the folder for the shank or the tetrode</b>, as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yaniklab/miniconda3/envs/klustaviewa/lib/python2.7/site-packages/IPython/qt.py:13: ShimWarning: The `IPython.qt` package has been deprecated since IPython 4.0. You should import from qtconsole instead.\n",
      "  \"You should import from qtconsole instead.\", ShimWarning)\n",
      "2018-07-12 14:04:35  kwikloader:133          Opening probe_0_group_0.kwik.\n",
      "/home/yaniklab/miniconda3/envs/klustaviewa/lib/python2.7/site-packages/numpy/core/_methods.py:55: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "2018-07-12 14:04:43  controller:51           Moved clusters [0] to 0\n",
      "2018-07-12 14:05:08  controller:51           Moved clusters [2] to 2\n",
      "2018-07-12 14:05:20  controller:51           Moved clusters [3] to 2\n",
      "2018-07-12 14:05:41  controller:51           Moved clusters [4] to 2\n",
      "2018-07-12 14:14:11  controller:51           Moved clusters [5] to 2\n",
      "2018-07-12 14:14:14  controller:51           Moved clusters [6] to 0\n",
      "2018-07-12 14:14:23  controller:51           Moved clusters [7] to 1\n",
      "2018-07-12 14:14:40  controller:51           Moved clusters [8] to 2\n",
      "2018-07-12 14:14:47  controller:51           Moved clusters [9] to 1\n",
      "2018-07-12 14:15:05  controller:51           Moved clusters [10] to 2\n",
      "2018-07-12 14:15:13  controller:51           Moved clusters [11] to 2\n",
      "2018-07-12 14:15:26  controller:51           Moved clusters [12] to 2\n",
      "2018-07-12 14:15:34  controller:51           Moved clusters [13] to 1\n",
      "2018-07-12 14:15:38  controller:51           Moved clusters [14] to 0\n",
      "2018-07-12 14:16:01  controller:51           Moved clusters [15] to 2\n",
      "2018-07-12 14:16:14  controller:51           Moved clusters [16] to 1\n",
      "2018-07-12 14:16:25  controller:51           Moved clusters [17] to 2\n",
      "2018-07-12 14:16:32  controller:51           Moved clusters [18] to 1\n",
      "2018-07-12 14:16:42  controller:51           Moved clusters [19] to 2\n",
      "2018-07-12 14:16:53  controller:51           Moved clusters [20] to 2\n",
      "2018-07-12 14:16:58  controller:51           Moved clusters [21] to 0\n",
      "2018-07-12 14:17:05  controller:51           Moved clusters [22] to 1\n",
      "2018-07-12 14:17:14  controller:51           Moved clusters [23] to 1\n",
      "2018-07-12 14:18:25  controller:51           Moved clusters [24] to 2\n",
      "2018-07-12 14:18:36  controller:51           Moved clusters [25] to 2\n",
      "2018-07-12 14:18:45  controller:51           Moved clusters [26] to 2\n",
      "2018-07-12 14:18:55  controller:51           Moved clusters [27] to 2\n",
      "2018-07-12 14:19:14  controller:51           Moved clusters [28] to 0\n",
      "2018-07-12 14:19:18  controller:51           Moved clusters [29] to 0\n",
      "2018-07-12 14:19:21  controller:51           Moved clusters [30] to 1\n",
      "2018-07-12 14:19:30  controller:51           Moved clusters [31] to 2\n",
      "2018-07-12 14:26:25  controller:51           Moved clusters [32] to 2\n",
      "2018-07-12 14:26:35  controller:51           Moved clusters [33] to 2\n",
      "2018-07-12 14:26:55  controller:51           Moved clusters [34] to 1\n",
      "2018-07-12 14:27:03  controller:51           Moved clusters [35] to 2\n",
      "2018-07-12 14:27:09  controller:51           Moved clusters [36] to 2\n",
      "2018-07-12 14:27:19  controller:51           Moved clusters [37] to 1\n",
      "2018-07-12 14:27:30  controller:51           Moved clusters [38] to 1\n",
      "2018-07-12 14:27:49  controller:51           Moved clusters [39] to 1\n",
      "2018-07-12 14:28:04  controller:51           Moved clusters [40] to 2\n",
      "2018-07-12 14:28:47  controller:51           Moved clusters [41] to 2\n",
      "2018-07-12 14:28:52  controller:51           Moved clusters [42] to 0\n",
      "2018-07-12 14:29:02  controller:51           Moved clusters [43] to 2\n",
      "2018-07-12 14:29:14  controller:51           Moved clusters [44] to 2\n",
      "2018-07-12 14:29:25  controller:51           Moved clusters [45] to 1\n",
      "2018-07-12 14:29:34  controller:51           Moved clusters [46] to 1\n",
      "2018-07-12 14:29:43  controller:51           Moved clusters [47] to 0\n",
      "2018-07-12 14:29:51  controller:51           Moved clusters [48] to 1\n",
      "2018-07-12 14:30:12  controller:51           Moved clusters [49] to 1\n",
      "2018-07-12 14:30:28  controller:51           Moved clusters [50] to 0\n",
      "2018-07-12 14:30:37  controller:51           Moved clusters [51] to 1\n",
      "2018-07-12 14:30:43  controller:51           Moved clusters [52] to 1\n",
      "2018-07-12 14:31:07  controller:51           Moved clusters [53] to 1\n",
      "2018-07-12 14:31:10  controller:51           Moved clusters [54] to 1\n",
      "2018-07-12 14:31:35  controller:51           Moved clusters [55] to 2\n",
      "2018-07-12 14:31:47  controller:51           Moved clusters [56] to 0\n",
      "2018-07-12 14:31:55  controller:51           Moved clusters [57] to 1\n",
      "2018-07-12 14:32:07  controller:51           Moved clusters [58] to 1\n",
      "2018-07-12 14:32:23  controller:51           Moved clusters [59] to 2\n",
      "2018-07-12 14:32:30  controller:51           Moved clusters [60] to 1\n",
      "2018-07-12 14:32:37  controller:51           Moved clusters [61] to 1\n",
      "2018-07-12 14:32:48  controller:51           Moved clusters [62] to 0\n",
      "2018-07-12 14:32:54  controller:51           Moved clusters [63] to 2\n",
      "2018-07-12 14:32:58  controller:51           Moved clusters [64] to 1\n",
      "2018-07-12 14:33:02  controller:51           Moved clusters [65] to 0\n",
      "2018-07-12 14:33:08  controller:51           Moved clusters [66] to 0\n",
      "2018-07-12 14:33:10  controller:51           Moved clusters [67] to 0\n",
      "2018-07-12 14:33:13  controller:51           Moved clusters [68] to 0\n",
      "2018-07-12 14:33:16  controller:51           Moved clusters [69] to 0\n",
      "2018-07-12 14:33:21  controller:51           Moved clusters [70] to 0\n",
      "2018-07-12 14:33:26  controller:51           Moved clusters [71] to 1\n",
      "2018-07-12 14:33:33  controller:51           Moved clusters [72] to 1\n",
      "2018-07-12 14:33:43  controller:51           Moved clusters [73] to 1\n",
      "2018-07-12 14:33:53  controller:51           Moved clusters [74] to 0\n",
      "2018-07-12 14:34:00  controller:51           Moved clusters [75] to 2\n",
      "2018-07-12 14:34:04  controller:51           Moved clusters [76] to 0\n",
      "2018-07-12 14:34:11  controller:51           Moved clusters [77] to 1\n",
      "2018-07-12 14:34:13  controller:51           Moved clusters [78] to 0\n",
      "2018-07-12 14:34:19  controller:51           Moved clusters [79] to 2\n",
      "2018-07-12 14:34:34  controller:51           Moved clusters [80] to 0\n",
      "2018-07-12 14:34:37  controller:51           Moved clusters [81] to 0\n",
      "2018-07-12 14:34:41  controller:51           Moved clusters [82] to 0\n",
      "2018-07-12 14:34:43  controller:51           Moved clusters [83] to 0\n",
      "2018-07-12 14:34:58  controller:51           Moved clusters [86] to 0\n",
      "2018-07-12 14:35:25  controller:51           Moved clusters [89] to 0\n",
      "2018-07-12 14:35:40  controller:51           Moved clusters [84 85 87 88 90 91] to 2\n",
      "<klustaviewa.gui.mainwindow.MainWindow object at 0x7f29c31c2640>\n",
      "QObject::startTimer: QTimer can only be used with threads started with QThread\n",
      "QObject::startTimer: QTimer can only be used with threads started with QThread\n",
      "(klustaviewa) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "klustaviewa \"/media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_05_04_FUSs1_EphysM1_E-FUS_NBBB80/analysis_files/probe_0_group_0/probe_0_group_0.kwik\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing the initial manual clustering process for a kwik file, <b>save the results and exit klustaviewa</b>. Then, <b>run the cell above again for the next .kwik file to be analyzed</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With the remaining clusters, we can extract the spike times and the waveforms from the .clu files first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<i> Troubleshoot: </i> If the error 'unsupported pickle' occurs try using the command <b> conda update conda </b> from the terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(klustaviewa) (klusta) /media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_03_29_FUSs1_EphysM1_E-FUS_NBBB62/FUS_Muscimol_180329_171634\n",
      "(klusta) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "PATHEXP='/media/yaniklab/05d01d78-2bd6-4a4e-b573-df49ccacb71c/2018_05_04_FUSs1_EphysM1_E-FUS_NBBB80/'\n",
    "source deactivate klustaviewa\n",
    "echo $PATHEXP|python extract_spikeinfo_from_all.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Generating PSTH graphs for all electrodes\n",
    "\n",
    "Next step is to generate PSTH graphs to see the response in time.\n",
    "Please, enter the parameters for signal analysis.\n",
    "Input time in ms before the stimulus, time in ms after the stimulus and bin size in ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 12:38:04.215 NotebookApp]\u001b(B\u001b[m The port 8888 is already in use, trying another port.\n",
      "\u001b[32m[I 12:38:04.215 NotebookApp]\u001b(B\u001b[m The port 8889 is already in use, trying another port.\n",
      "\u001b[32m[I 12:38:04.222 NotebookApp]\u001b(B\u001b[m Serving notebooks from local directory: /home/yaniklab/Desktop/akgokce/hybrid2\n",
      "\u001b[32m[I 12:38:04.222 NotebookApp]\u001b(B\u001b[m 0 active kernels \n",
      "\u001b[32m[I 12:38:04.222 NotebookApp]\u001b(B\u001b[m The Jupyter Notebook is running at: http://localhost:8890/?token=018fa981ec89ad547697e1af642c01fc4ae4f5625fffa1e4\n",
      "\u001b[32m[I 12:38:04.222 NotebookApp]\u001b(B\u001b[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "[C 12:38:04.223 NotebookApp] \n",
      "    \n",
      "    Copy/paste this URL into your browser when you connect for the first time,\n",
      "    to login with a token:\n",
      "        http://localhost:8890/?token=018fa981ec89ad547697e1af642c01fc4ae4f5625fffa1e4\n",
      "\u001b[32m[I 12:38:04.698 NotebookApp]\u001b(B\u001b[m Accepting one-time-token-authenticated connection from 127.0.0.1\n",
      "\u001b[32m[I 12:38:05.517 NotebookApp]\u001b(B\u001b[m Kernel started: 78ee990c-2f7e-4155-a8e8-0c3bb860096b\n",
      "\u001b[32m[I 12:40:05.518 NotebookApp]\u001b(B\u001b[m Saving file at /PSTH_pipeline.ipynb\n",
      "\u001b[32m[I 12:42:05.519 NotebookApp]\u001b(B\u001b[m Saving file at /PSTH_pipeline.ipynb\n",
      "\u001b[32m[I 12:50:05.519 NotebookApp]\u001b(B\u001b[m Saving file at /PSTH_pipeline.ipynb\n",
      "\u001b[32m[I 12:52:05.520 NotebookApp]\u001b(B\u001b[m Saving file at /PSTH_pipeline.ipynb\n"
     ]
    }
   ],
   "source": [
    "jupyter notebook './PSTH_pipeline.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! \n",
    "\n",
    "You can check the <i> Analyzed </i> folder to see the plots and the excel sheets containing the evoked LFP data and <b> move the files and folders </b> that you deem necessary into the <i> Analyzed </i> folder inside the <i> Electrophysiology </i> Dropbox folder. Please do not forget to rename the folder with the date and the name of the experiment when adding to the <i> Analyzed </i> folder. At the end, please <b> delete the data and the intermediate files from the SSD. </b> \n",
    "\n",
    "Notebook written by Baran Yasar in 04/2017. Please contact him in person or via e-mail at yasar@biomed.ee.ethz.ch in case of any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
